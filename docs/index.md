# avisual memories

> **The only AI memory system that prevents mistakes _before_ they happen.**

## What is avisual memories?

avisual memories is a brain-like memory system for AI agents that provides:

- **Persistent long-term memory** across sessions
- **Neural-inspired retrieval** via spreading activation
- **Antipatterns** that warn agents before repeating mistakes
- **Hebbian learning** that automatically strengthens connections
- **Memory consolidation** that decays, merges, and prunes old knowledge
- **Local-first design** with no API costs (uses Ollama)

## Why avisual memories?

Unlike basic RAG systems or commercial memory APIs, avisual memories is built like an actual brain:

| Feature | avisual memories | Mem0 | LangChain | ChromaDB |
|---------|------------------|------|-----------|----------|
| **Antipatterns** | âœ… | âŒ | âŒ | âŒ |
| Spreading activation | âœ… | âŒ | âŒ | âŒ |
| Hebbian learning | âœ… | âŒ | âŒ | âŒ |
| Memory consolidation | âœ… | âŒ | âŒ | âŒ |
| Local-first | âœ… | âŒ | âœ… | âœ… |
| Open source (MIT) | âœ… | âŒ | âœ… | âœ… |
| Cost | **Free** | $249/mo | Free | Free |

## Quick Start

```bash
# Install
pip install avisual-memories

# Setup (interactive)
avisual-memories setup --interactive

# Verify
avisual-memories diagnose
```

Then restart your AI agent (Claude Code, Aider, etc.) and it will have persistent memory!

## Key Features

### ğŸš¨ Antipatterns

The killer feature. When your agent tries to repeat a past mistake, memories surfaces a warning _before_ the command runs.

**Example:**
```python
# Agent previously used rm and lost important files
# Stored as antipattern: "Use trash instead of rm for safety"

# Later session, agent tries:
os.system("rm important_file.txt")

# Memory warning appears:
# âš ï¸ ANTIPATTERN: Use trash instead of rm for safety
# Related to: file deletion (similarity: 0.92)
```

â†’ [Learn more about antipatterns](concepts/antipatterns.md)

### ğŸ§  Spreading Activation

When you recall one memory, activation flows through connected memories like neural pathways, surfacing related knowledge you didn't search for.

**Example:**
```python
recall(query="Etsy shop setup")

# Returns not just Etsy docs, but also:
# - "Browser automation on Etsy requires human-like pauses"
# - "Sign in with Apple bypasses bot detection"
# - "Printify API is better than browser automation"
```

â†’ [Learn more about spreading activation](concepts/spreading-activation.md)

### ğŸ”— Hebbian Learning

"Neurons that fire together wire together." When memories are recalled together, their connection strengthens automatically.

**Example:**
```python
# Agent recalls "Python" and "testing" in same session
# Connection "Python" â† testing â†’ "pytest" strengthens

# Next time: recalling "Python" automatically surfaces "pytest"
```

â†’ [Learn more about Hebbian learning](concepts/hebbian-learning.md)

### ğŸ§¹ Memory Consolidation

Like sleep for your AI's brain. Periodically:
- Decays old, unused memories
- Merges duplicate knowledge
- Prunes weak connections
- Promotes important patterns

â†’ [Learn more about consolidation](concepts/consolidation.md)

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   AI Agent                       â”‚
â”‚         (Claude Code, Aider, etc.)               â”‚
â”‚                                                  â”‚
â”‚  Hooks: UserPromptSubmit â†’ Recall context       â”‚
â”‚         PostToolUse â†’ Learn from errors          â”‚
â”‚         Stop â†’ Hebbian learning                  â”‚
â”‚                                                  â”‚
â”‚  MCP Tools: remember, recall, connect,           â”‚
â”‚             forget, amend, reflect, etc.          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              avisual memories                     â”‚
â”‚                                                  â”‚
â”‚  Brain â”€â”€â†’ Retrieval (spreading activation)      â”‚
â”‚        â”€â”€â†’ Learning (Hebbian, auto-linking)       â”‚
â”‚        â”€â”€â†’ Consolidation (decay, merge, prune)   â”‚
â”‚        â”€â”€â†’ Context (budget compression)          â”‚
â”‚                                                  â”‚
â”‚  Storage: SQLite + sqlite-vec + FTS5             â”‚
â”‚  Embeddings: Ollama (nomic-embed-text)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Performance

- **602 atoms/sec** creation rate
- **1,128 synapses/sec** connection rate
- **0.7ms** average search query
- **1,545 recalls/sec** retrieval throughput

Tested with 1,000-atom datasets. See [benchmarks](https://github.com/avisual/memories/tree/main/tests/load).

## Use Cases

- **Claude Code** - Give Claude persistent memory across sessions
- **Aider** - Remember codebase patterns and past mistakes
- **Custom AI agents** - Any agent using MCP protocol
- **Research assistants** - Build knowledge graphs over time
- **Debugging agents** - Learn from errors, prevent repeats

## Next Steps

- [Installation Guide](getting-started/installation.md)
- [Quick Start Tutorial](getting-started/quick-start.md)
- [Antipatterns Deep Dive](concepts/antipatterns.md)
- [API Reference](api/mcp-tools.md)
- [Best Practices](guides/best-practices.md)

## Support

- **GitHub Issues**: [github.com/avisual/memories/issues](https://github.com/avisual/memories/issues)
- **Documentation**: [avisual.github.io/memories](https://avisual.github.io/memories)
- **PyPI**: [pypi.org/project/avisual-memories](https://pypi.org/project/avisual-memories/)

## License

MIT - see [LICENSE](license.md) for details.
